# awesome-controllable-editing-SD

A Survey of Controllable Editing Stable Diffusion

## Papers

### Cones: Concept Neurons in Diffusion Models for Customized Generation ([arxiv](https://arxiv.org/abs/2303.05125), 9 Mar 2023)

1. Problem: Can modern deep neural networks exhibit behavior patterns similar to the human brain's response to semantic features of presented stimuli with different neurons?
2. Solution: This paper identifies a small cluster of neurons in a diffusion model corresponding to a particular subject and calls them concept neurons. These neurons demonstrate magnetic properties in interpreting and manipulating generation results, and concatenating multiple clusters of concept neurons can generate all related concepts in a single image
3. Insight: The concept neurons can be identified by statistics of network gradients to a stimulation connected with the given subject and can reduce storage consumption by 90% compared to previous subject-driven generation methods. Extensive qualitative and quantitative studies on diverse datasets confirm the effectiveness and efficiency of the proposed approach.
4. Limitation: The approach may be limited to generating up to four different subjects in a single image.

### Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles ([arixv](https://arxiv.org/abs/2303.03751), 7 Mar 2023)

1. Problem: Objective function is a black-box and can only be evaluated through a ranking oracle.
2. Solution: ZO-RankSGD, a zeroth-order optimization algorithm with a new rank-based random estimator for the descent direction, is proposed to solve the problem.
3. Insight: ZO-RankSGD can be applied to the policy search problem in reinforcement learning when only a ranking oracle of the episode reward is available, making it a promising alternative to existing Reinforcement Learning with Human Feedback (RLHF) methods.
4. Limitation: The effectiveness of ZO-RankSGD is demonstrated only in improving the quality of images generated by a diffusion generator.

### X&Fuse: Fusing Visual Information in Text-to-Image Generation ([arxiv](https://arxiv.org/abs/2303.01000), 2 Mar 2023)

1. Problem: Generating images from text while incorporating visual information.
2. Solution: X&Fuse approach that conditions on visual information in three scenarios: Retrieve&Fuse, Crop&Fuse, and Scene&Fuse.
3. Insight: X&Fuse is an effective, easy-to-adapt, simple, and general approach for scenarios in which the model may benefit from additional visual information.

### ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation ([arxiv](https://arxiv.org/abs/2302.13848), 27 Feb 2023)

1. Problem: Existing methods for customized text-to-image generation often rely on optimization-based approaches, which can be computationally intensive and memory-intensive.
2. Solution: The authors propose a learning-based encoder that consists of global and local mapping networks for fast and accurate concept customization. The global mapping network projects hierarchical image features into multiple words in the textual word embedding space, while the local mapping network injects encoded patch features into cross attention layers for additional details.
3. Insight: The proposed method enables high-fidelity inversion and robust editability of primary concepts while excluding irrelevant disturbances, with a significantly faster encoding process compared to prior optimization-based approaches.
4. Limitation: The limitations of the proposed method are not explicitly stated in the abstract.

### Encoder-based Domain Tuning for Fast Personalization of Text-to-Image Models([arxiv](https://arxiv.org/abs/2302.12228), 23 Feb 2023)

1. Problem: Current text-to-image personalization approaches have limitations in terms of lengthy training times, high storage requirements, or loss of identity.
2. Solution: Encoder-based domain tuning approach by underfitting on a large set of concepts from a given domain, employing an encoder and regularized weight-offsets for the text-to-image model.
3. Insight: Underfitting on a large set of concepts from a given domain improves generalization and creates a model that is more amenable to quickly adding novel concepts from the same domain.
4. Limitation: The proposed approach may not generalize well to domains with highly diverse or unrelated concep

A Survey of Controllable Editing Stable Diffusion
